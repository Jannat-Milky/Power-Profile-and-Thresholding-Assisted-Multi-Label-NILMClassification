{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11278724,"sourceType":"datasetVersion","datasetId":7051369}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\"\"\"\nCORRECTED VERSION: Power Profile and Thresholding Assisted Multi-Label NILM Classification\nPaper Replication with Dynamic Dataset Adaptation\n\nAuthor: Research Replication Team\nDate: 2024\n\nThis code correctly replicates the methodology from the paper:\n\"Power Profile and Thresholding Assisted Multi-Label NILM Classification\"\n\nDataset path: /kaggle/input/redd-dataset/redd\n\nCORRECTIONS APPLIED:\n1. Dynamic dataset discovery instead of hardcoded channel mapping\n2. House 2 support with actual appliance data\n3. Proper power windowing based on actual data\n4. Correct OPM thresholding implementation\n\"\"\"\n\nimport os\nimport sys\nimport numpy as np\nimport pandas as pd\nimport glob\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Machine Learning libraries\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler\n\n# Visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tqdm import tqdm\nimport time\nimport joblib\n\n# Set paths\nDATA_PATH = \"/kaggle/input/redd-dataset/redd\"\nOUTPUT_PATH = \"/kaggle/working/\"\n\n# Create output directory\nos.makedirs(OUTPUT_PATH, exist_ok=True)\n\n# ===================== CORRECTED CONFIGURATION =====================\n\nclass Config:\n    \"\"\"Dynamic configuration based on actual dataset\"\"\"\n    \n    HOUSE_NUMBER = 2  # Using House 2 as it has actual appliance data\n    \n    # Paper's power windows for reference (from Table 3)\n    PAPER_POWER_WINDOWS = {\n        'dish_washer': (30, 1200),\n        'electric_stove': (1000, 1500),\n        'fridge': (175, 500),\n        'microwave': (20, 1650),\n        'washer_dryer': (250, 700),\n        'refrigerator': (175, 500),  # Same as fridge\n        'stove': (1000, 1500),  # Same as electric_stove\n        'kitchen_outlet': (10, 150),\n        'lighting': (20, 400),\n        'bathroom_gfi': (1500, 1700),\n        'electric_heater': (1, 21),\n    }\n    \n    # Threshold values (OPM) as in paper\n    THRESHOLDS = [5, 10, 20, 30, 40, 50]\n    \n    # Experimental scenarios\n    WINDOWING_SCENARIOS = [True, False]\n    \n    # Training parameters\n    RANDOM_STATE = 42\n    TEST_SIZE = 0.2\n    \n    # Use all samples for OPM calculation (critical for paper methodology)\n    SAMPLE_SIZE = None  # None means use all data\n\n# ===================== CORRECTED DATA LOADER =====================\n\nclass REDDDataLoader:\n    \"\"\"Loads and preprocesses REDD dataset with dynamic appliance discovery\"\"\"\n    \n    def __init__(self, data_path, house_number=2):\n        self.data_path = data_path\n        self.house_number = house_number\n        \n        # Discover actual appliances in dataset\n        self.appliance_names = self.discover_appliances()\n        self.power_windows = self.set_power_windows()\n        \n        print(f\"Discovered {len(self.appliance_names)} appliances: {self.appliance_names}\")\n    \n    def discover_appliances(self):\n        \"\"\"Discover actual appliances in the dataset files\"\"\"\n        pattern = os.path.join(self.data_path, f\"*house{self.house_number}_*.csv\")\n        csv_files = glob.glob(pattern)\n        \n        if not csv_files:\n            raise FileNotFoundError(f\"No CSV files found for house {self.house_number}\")\n        \n        # Load first file to discover structure\n        df_sample = pd.read_csv(csv_files[0])\n        \n        # Find appliance columns (not 'main' and not unnamed)\n        appliance_cols = []\n        for col in df_sample.columns:\n            col_lower = str(col).lower().strip()\n            if col_lower != 'main' and not col_lower.startswith('unnamed'):\n                # Clean column name\n                clean_name = col_lower.replace('#', '').replace(' ', '_').strip()\n                if clean_name and clean_name != 'main':\n                    appliance_cols.append(clean_name)\n        \n        # Remove duplicates and sort\n        appliance_cols = sorted(list(set(appliance_cols)))\n        \n        return appliance_cols\n    \n    def set_power_windows(self):\n        \"\"\"Set power windows based on paper's values or data statistics\"\"\"\n        windows = {}\n        \n        # Load sample data to get power statistics\n        pattern = os.path.join(self.data_path, f\"*house{self.house_number}_0.csv\")\n        csv_files = glob.glob(pattern)\n        \n        if csv_files:\n            df_sample = pd.read_csv(csv_files[0])\n            \n            for appliance in self.appliance_names:\n                # Try to find the column in the dataframe\n                matching_cols = [col for col in df_sample.columns \n                               if str(col).lower().replace('#', '').replace(' ', '_').strip() == appliance]\n                \n                if matching_cols:\n                    col_name = matching_cols[0]\n                    power_data = df_sample[col_name]\n                    \n                    # Use paper's window if available, otherwise use data statistics\n                    if appliance in Config.PAPER_POWER_WINDOWS:\n                        windows[appliance] = Config.PAPER_POWER_WINDOWS[appliance]\n                    else:\n                        # Calculate from data: use 5th and 95th percentiles to remove outliers\n                        min_power = max(0, power_data.quantile(0.05))\n                        max_power = power_data.quantile(0.95)\n                        \n                        # Ensure minimum range\n                        if max_power - min_power < 10:\n                            max_power = min_power + 100  # Default range\n                        \n                        windows[appliance] = (float(min_power), float(max_power))\n        \n        return windows\n    \n    def _standardize_column_names(self, df):\n        \"\"\"Standardize column names across CSV files - CORRECTED for actual REDD format\"\"\"\n        new_columns = {}\n        \n        for col in df.columns:\n            col_str = str(col)\n            col_lower = col_str.lower().strip()\n            \n            # Clean the column name\n            clean_name = col_lower.replace('#', '').replace(' ', '_').replace('__', '_').strip()\n            \n            # Map to standard names\n            if 'main' in clean_name or col_str == 'main':\n                new_columns[col] = 'main'\n            elif any(appliance in clean_name for appliance in self.appliance_names):\n                # Find the matching appliance\n                for appliance in self.appliance_names:\n                    if appliance in clean_name:\n                        new_columns[col] = appliance\n                        break\n                else:\n                    new_columns[col] = clean_name\n            else:\n                new_columns[col] = clean_name\n        \n        df = df.rename(columns=new_columns)\n        \n        # Ensure all appliance columns exist\n        for appliance in self.appliance_names:\n            if appliance not in df.columns:\n                df[appliance] = 0.0\n        \n        return df\n    \n    def load_house_data(self, sample_size=None):\n        \"\"\"Load all CSV files for a house and merge them correctly\"\"\"\n        pattern = os.path.join(self.data_path, f\"*house{self.house_number}_*.csv\")\n        csv_files = sorted(glob.glob(pattern))\n        \n        if not csv_files:\n            raise FileNotFoundError(f\"No CSV files found for house {self.house_number}\")\n        \n        print(f\"Found {len(csv_files)} files for house {self.house_number}\")\n        \n        dfs = []\n        \n        for file in tqdm(csv_files, desc=\"Loading CSV files\"):\n            try:\n                df = pd.read_csv(file)\n                \n                # Standardize column names\n                df = self._standardize_column_names(df)\n                \n                # Ensure we have main column\n                if 'main' not in df.columns:\n                    print(f\"Warning: 'main' not found in {file}, skipping\")\n                    continue\n                \n                # Handle missing values - fill with 0 for appliances\n                for col in df.columns:\n                    if col != 'main':\n                        df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)\n                \n                dfs.append(df)\n                \n            except Exception as e:\n                print(f\"Error reading {file}: {str(e)[:100]}\")\n                continue\n        \n        if not dfs:\n            raise ValueError(\"No valid data loaded\")\n        \n        # Combine all dataframes\n        combined_df = pd.concat(dfs, ignore_index=True)\n        \n        # Ensure numeric types\n        for col in combined_df.columns:\n            combined_df[col] = pd.to_numeric(combined_df[col], errors='coerce')\n        \n        # Fill any remaining NaN values\n        combined_df = combined_df.fillna(0)\n        \n        # Sample if requested\n        if sample_size and len(combined_df) > sample_size:\n            print(f\"Note: Using {sample_size:,} samples out of {len(combined_df):,}\")\n            combined_df = combined_df.iloc[:sample_size]\n        \n        print(f\"Loaded {len(combined_df):,} samples\")\n        print(f\"Available columns: {list(combined_df.columns)}\")\n        \n        return combined_df\n    \n    def apply_power_windowing(self, df, verbose=True):\n        \"\"\"Apply power windowing as per paper methodology - CORRECTED\"\"\"\n        df_processed = df.copy()\n        \n        if verbose:\n            print(\"\\n\" + \"=\"*80)\n            print(\"Applying Power Windowing (Corrected Implementation)\")\n            print(\"=\"*80)\n        \n        stats = []\n        \n        for appliance in self.appliance_names:\n            if appliance not in df_processed.columns:\n                continue\n            \n            power_data = df_processed[appliance]\n            \n            # Get power window for this appliance\n            if appliance in self.power_windows:\n                lower, upper = self.power_windows[appliance]\n            else:\n                # Default: use 5th and 95th percentiles\n                lower = float(power_data.quantile(0.05))\n                upper = float(power_data.quantile(0.95))\n                self.power_windows[appliance] = (lower, upper)\n            \n            # Calculate states before windowing\n            before_on = (power_data > 0).sum()\n            \n            # Create state column: 1 if within window, 0 otherwise\n            state_series = ((power_data >= lower) & (power_data <= upper)).astype(int)\n            df_processed[f\"{appliance}_state\"] = state_series\n            \n            # Store windowed power for analysis\n            df_processed[f\"{appliance}_windowed\"] = power_data.copy()\n            outside_window = ~((power_data >= lower) & (power_data <= upper))\n            df_processed.loc[outside_window, f\"{appliance}_windowed\"] = 0\n            \n            after_on = state_series.sum()\n            \n            stats.append({\n                'appliance': appliance,\n                'window': (lower, upper),\n                'before_on': before_on,\n                'after_on': after_on,\n                'changed': before_on - after_on,\n                'pct_on_before': (before_on / len(df)) * 100,\n                'pct_on_after': (after_on / len(df)) * 100\n            })\n        \n        if verbose:\n            print(f\"\\n{'Appliance':<20} {'Window (W)':<15} {'Before ON':<10} {'After ON':<10} {'Changed':<10} {'% ON Before':<12} {'% ON After':<12}\")\n            print(\"-\"*90)\n            \n            for stat in stats:\n                window_str = f\"{stat['window'][0]:.0f}-{stat['window'][1]:.0f}\"\n                print(f\"{stat['appliance']:<20} {window_str:<15} {stat['before_on']:<10,} {stat['after_on']:<10,} \"\n                      f\"{stat['changed']:<10,} {stat['pct_on_before']:<12.1f} {stat['pct_on_after']:<12.1f}\")\n        \n        return df_processed\n    \n    def create_binary_labels_no_windowing(self, df):\n        \"\"\"Create binary labels without power windowing (paper baseline) - CORRECTED\"\"\"\n        df_labels = df.copy()\n        \n        for appliance in self.appliance_names:\n            if appliance in df_labels.columns:\n                # PAPER BASELINE: Simple ON/OFF (>0)\n                df_labels[f\"{appliance}_state\"] = (df_labels[appliance] > 0).astype(int)\n        \n        return df_labels\n    \n    def create_multiclass_labels(self, df, threshold=5, verbose=True):\n        \"\"\"Create multiclass labels and apply thresholding (OPM) - CORRECTED\"\"\"\n        \n        # Get state columns\n        state_columns = [col for col in df.columns if col.endswith('_state')]\n        \n        if not state_columns:\n            raise ValueError(\"No state columns found. Run power windowing or binary labeling first.\")\n        \n        # Sort to ensure consistent ordering\n        state_columns = sorted(state_columns)\n        \n        # Create binary combination string (PAPER METHOD)\n        df['binary_combination'] = df[state_columns].astype(str).agg(''.join, axis=1)\n        \n        # Apply thresholding (OPM)\n        combination_counts = df['binary_combination'].value_counts()\n        \n        if verbose:\n            print(f\"\\nThresholding Analysis (Threshold = {threshold}):\")\n            print(f\"Total samples: {len(df):,}\")\n            print(f\"Unique combinations before thresholding: {len(combination_counts)}\")\n        \n        # Remove combinations below threshold\n        valid_combinations = combination_counts[combination_counts >= threshold].index\n        mask = df['binary_combination'].isin(valid_combinations)\n        df_filtered = df[mask].copy()\n        \n        if verbose:\n            print(f\"Unique combinations after thresholding: {len(valid_combinations)}\")\n            print(f\"Samples after thresholding: {len(df_filtered):,} ({len(df_filtered)/len(df)*100:.1f}%)\")\n            print(f\"Removed samples: {len(df) - len(df_filtered):,}\")\n        \n        # Show top combinations\n        print(\"\\nTop 10 appliance combinations:\")\n        top_combos = combination_counts.head(10)\n        \n        for combo, count in top_combos.items():\n            # Map binary string to appliance names\n            appliance_states = []\n            for i, (app, state) in enumerate(zip(state_columns, combo)):\n                app_name = app.replace('_state', '')\n                appliance_states.append(f\"{app_name[:3]}:{state}\")\n            \n            state_str = \"|\".join(appliance_states)\n            print(f\"  {combo} : {state_str} : {count:7,d} occurrences\")\n        \n        # Encode labels\n        label_encoder = LabelEncoder()\n        df_filtered['encoded_label'] = label_encoder.fit_transform(df_filtered['binary_combination'])\n        \n        # PAPER METHOD: Use only aggregate power as feature\n        X = df_filtered[['main']].values.astype(np.float32)\n        y = df_filtered['encoded_label'].values\n        \n        # Handle any NaN values\n        X = np.nan_to_num(X, nan=0.0)\n        \n        # Get class distribution\n        unique_classes, class_counts = np.unique(y, return_counts=True)\n        \n        if verbose:\n            print(f\"\\nFinal dataset for ML:\")\n            print(f\"  Features shape: {X.shape}\")\n            print(f\"  Labels shape: {y.shape}\")\n            print(f\"  Number of classes: {len(unique_classes)}\")\n            \n            # Show class distribution\n            print(\"\\n  Class distribution (top 10):\")\n            sorted_indices = np.argsort(-class_counts)\n            for i, idx in enumerate(sorted_indices[:10]):\n                class_id = unique_classes[idx]\n                count = class_counts[idx]\n                combo = label_encoder.inverse_transform([class_id])[0]\n                print(f\"    Class {class_id:3d}: {count:7,d} samples - {combo}\")\n        \n        return X, y, label_encoder, df_filtered\n\n# ===================== MACHINE LEARNING CLASSIFIERS (UNCHANGED) =====================\n\nclass NILMClassifier:\n    \"\"\"Machine learning classifiers as per paper\"\"\"\n    \n    def __init__(self, random_state=42):\n        self.random_state = random_state\n        self.scaler = StandardScaler()\n        self.classifiers = {}\n        self.results = {}\n        self.training_times = {}\n        self._initialize_classifiers()\n    \n    def _initialize_classifiers(self):\n        \"\"\"Initialize classifiers with paper parameters (Table 2)\"\"\"\n        self.classifiers = {\n            'CART': DecisionTreeClassifier(\n                criterion='gini',\n                splitter='best',\n                min_samples_split=2,\n                min_samples_leaf=1,\n                random_state=self.random_state\n            ),\n            'ET': ExtraTreesClassifier(\n                n_estimators=100,\n                criterion='gini',\n                min_samples_split=2,\n                min_samples_leaf=1,\n                random_state=self.random_state,\n                n_jobs=-1\n            ),\n            'KNN': KNeighborsClassifier(\n                n_neighbors=5,\n                weights='uniform',\n                metric='minkowski',\n                n_jobs=-1\n            ),\n            'KNN-CB': KNeighborsClassifier(\n                n_neighbors=10,\n                weights='distance',\n                metric='manhattan',\n                n_jobs=-1\n            ),\n            'LDA': LinearDiscriminantAnalysis(\n                solver='svd',\n                shrinkage=None,\n                tol=1e-4\n            ),\n            'NB': GaussianNB(var_smoothing=1e-9),\n            'RF': RandomForestClassifier(\n                n_estimators=100,\n                criterion='gini',\n                min_samples_split=2,\n                min_samples_leaf=1,\n                random_state=self.random_state,\n                n_jobs=-1\n            )\n        }\n        print(f\"Initialized {len(self.classifiers)} classifiers\")\n    \n    def train_and_evaluate(self, X_train, X_test, y_train, y_test):\n        \"\"\"Train and evaluate all classifiers\"\"\"\n        print(\"\\n\" + \"=\"*60)\n        print(\"Training and Evaluating Classifiers\")\n        print(\"=\"*60)\n        \n        # Scale features (aggregate power)\n        X_train_scaled = self.scaler.fit_transform(X_train)\n        X_test_scaled = self.scaler.transform(X_test)\n        \n        # Ensure no NaN\n        X_train_scaled = np.nan_to_num(X_train_scaled, nan=0.0)\n        X_test_scaled = np.nan_to_num(X_test_scaled, nan=0.0)\n        \n        self.results = {}\n        self.training_times = {}\n        \n        for name, clf in tqdm(self.classifiers.items(), desc=\"Training classifiers\"):\n            try:\n                # Training\n                start_time = time.time()\n                clf.fit(X_train_scaled, y_train)\n                train_time = time.time() - start_time\n                self.training_times[name] = train_time\n                \n                # Predictions\n                y_pred = clf.predict(X_test_scaled)\n                \n                # Calculate metrics (PAPER METRICS)\n                results = {\n                    'accuracy': accuracy_score(y_test, y_pred),\n                    'precision_macro': precision_score(y_test, y_pred, average='macro', zero_division=0),\n                    'recall_macro': recall_score(y_test, y_pred, average='macro', zero_division=0),\n                    'f1_macro': f1_score(y_test, y_pred, average='macro', zero_division=0),\n                    'precision_weighted': precision_score(y_test, y_pred, average='weighted', zero_division=0),\n                    'recall_weighted': recall_score(y_test, y_pred, average='weighted', zero_division=0),\n                    'f1_weighted': f1_score(y_test, y_pred, average='weighted', zero_division=0),\n                    'training_time': train_time,\n                    'n_classes': len(np.unique(y_train))\n                }\n                \n                self.results[name] = results\n                \n                print(f\"\\n✓ {name}: Trained in {train_time:.2f}s\")\n                print(f\"  Macro F1: {results['f1_macro']:.4f}\")\n                print(f\"  Weighted F1: {results['f1_weighted']:.4f}\")\n                print(f\"  Accuracy: {results['accuracy']:.4f}\")\n                \n            except Exception as e:\n                print(f\"\\n✗ Error with {name}: {str(e)[:100]}\")\n                self.results[name] = None\n        \n        return self.results\n\n# ===================== CORRECTED EXPERIMENT PIPELINE =====================\n\ndef run_experiment_pipeline(data_path, house_number=2, threshold=10,\n                           apply_windowing=True, sample_size=None):\n    \"\"\"\n    Complete experiment pipeline for one configuration - CORRECTED\n    \n    Args:\n        data_path: Path to REDD dataset\n        house_number: House number to process\n        threshold: OPM threshold value\n        apply_windowing: Whether to apply power windowing\n        sample_size: Number of samples to use (None for all)\n    \n    Returns:\n        Dictionary with experiment results\n    \"\"\"\n    print(f\"\\n{'#'*80}\")\n    print(f\"EXPERIMENT: House {house_number}, Threshold={threshold}, \"\n          f\"Windowing={'ON' if apply_windowing else 'OFF'}\")\n    print(f\"{'#'*80}\")\n    \n    # Step 1: Initialize loader and discover actual data\n    loader = REDDDataLoader(data_path, house_number)\n    \n    # Step 2: Load data\n    df = loader.load_house_data(sample_size=sample_size)\n    \n    # Step 3: Apply power windowing or binary labeling\n    if apply_windowing:\n        df_processed = loader.apply_power_windowing(df, verbose=True)\n    else:\n        df_processed = loader.create_binary_labels_no_windowing(df)\n        print(\"\\nUsing binary labeling without power windowing (paper baseline)\")\n    \n    # Step 4: Create multiclass labels with thresholding\n    try:\n        X, y, label_encoder, df_filtered = loader.create_multiclass_labels(\n            df_processed, threshold=threshold, verbose=True\n        )\n    except ValueError as e:\n        print(f\"\\nError creating multiclass labels: {e}\")\n        print(\"Skipping this configuration...\")\n        return None\n    \n    # Step 5: Split data\n    X_train, X_test, y_train, y_test = train_test_split(\n        X, y, test_size=Config.TEST_SIZE,\n        random_state=Config.RANDOM_STATE,\n        stratify=y\n    )\n    \n    print(f\"\\nData split:\")\n    print(f\"  Training samples: {len(X_train):,}\")\n    print(f\"  Testing samples: {len(X_test):,}\")\n    print(f\"  Feature dimension: {X.shape[1]}\")\n    print(f\"  Number of classes: {len(np.unique(y))}\")\n    \n    # Step 6: Train and evaluate classifiers\n    classifier = NILMClassifier(random_state=Config.RANDOM_STATE)\n    results = classifier.train_and_evaluate(X_train, X_test, y_train, y_test)\n    \n    # Step 7: Plot results\n    exp_name = f\"House{house_number}_Th{threshold}_Windowing{apply_windowing}\"\n    \n    # Step 8: Save results\n    results_summary = {\n        'config': {\n            'house_number': house_number,\n            'threshold': threshold,\n            'windowing': apply_windowing,\n            'n_samples': len(X),\n            'n_classes': len(np.unique(y)),\n            'n_train': len(X_train),\n            'n_test': len(X_test),\n            'appliances': loader.appliance_names,\n            'power_windows': loader.power_windows\n        },\n        'results': results,\n        'label_encoder': label_encoder\n    }\n    \n    # Save results\n    results_file = os.path.join(OUTPUT_PATH, f'results_{exp_name}.pkl')\n    joblib.dump(results_summary, results_file)\n    print(f\"\\nResults saved to: {results_file}\")\n    \n    return results_summary\n\n# ===================== DATASET ANALYSIS FUNCTIONS =====================\n\ndef analyze_dataset_structure(data_path):\n    \"\"\"Analyze the structure of the REDD dataset\"\"\"\n    print(\"\\n\" + \"=\"*80)\n    print(\"REDD DATASET STRUCTURE ANALYSIS\")\n    print(\"=\"*80)\n    \n    # List all houses\n    pattern = os.path.join(data_path, \"*.csv\")\n    all_files = glob.glob(pattern)\n    \n    houses = set()\n    for file in all_files:\n        filename = os.path.basename(file)\n        if 'house' in filename:\n            # Extract house number\n            parts = filename.split('_')\n            for part in parts:\n                if part.startswith('house'):\n                    house_num = part.replace('house', '')\n                    if house_num.isdigit():\n                        houses.add(int(house_num))\n    \n    print(f\"Houses found: {sorted(houses)}\")\n    \n    # Analyze each house\n    for house in sorted(houses)[:3]:  # Analyze first 3 houses\n        print(f\"\\n{'='*40}\")\n        print(f\"ANALYZING HOUSE {house}\")\n        print(f\"{'='*40}\")\n        \n        pattern = os.path.join(data_path, f\"*house{house}_*.csv\")\n        house_files = sorted(glob.glob(pattern))\n        \n        if not house_files:\n            print(f\"  No files found for house {house}\")\n            continue\n        \n        print(f\"  Found {len(house_files)} files\")\n        \n        # Check first file\n        first_file = house_files[0]\n        df = pd.read_csv(first_file)\n        \n        print(f\"\\n  First file: {os.path.basename(first_file)}\")\n        print(f\"  Shape: {df.shape}\")\n        print(f\"  Columns: {list(df.columns)}\")\n        \n        # Check for appliance data\n        appliance_cols = []\n        for col in df.columns:\n            col_lower = str(col).lower()\n            if 'main' not in col_lower and not col_lower.startswith('unnamed'):\n                appliance_cols.append(col)\n        \n        print(f\"  Appliance columns ({len(appliance_cols)}): {appliance_cols}\")\n        \n        # Show data sample\n        print(f\"\\n  Data sample (first 5 rows):\")\n        print(df.head().T)\n\ndef run_house_experiment(house_number=2, sample_size=100000):\n    \"\"\"Run experiment for a specific house\"\"\"\n    print(\"\\n\" + \"=\"*80)\n    print(f\"RUNNING EXPERIMENT FOR HOUSE {house_number}\")\n    print(\"=\"*80)\n    \n    all_results = {}\n    \n    # Test different configurations\n    for apply_windowing in Config.WINDOWING_SCENARIOS:\n        scenario_name = \"With_Windowing\" if apply_windowing else \"Without_Windowing\"\n        all_results[scenario_name] = {}\n        \n        for threshold in Config.THRESHOLDS:\n            print(f\"\\n{'='*60}\")\n            print(f\"Configuration: {scenario_name}, Threshold={threshold}\")\n            print(f\"{'='*60}\")\n            \n            # Run experiment\n            results = run_experiment_pipeline(\n                data_path=DATA_PATH,\n                house_number=house_number,\n                threshold=threshold,\n                apply_windowing=apply_windowing,\n                sample_size=sample_size\n            )\n            \n            if results:\n                all_results[scenario_name][threshold] = results\n    \n    # Generate summary\n    print(\"\\n\" + \"#\"*80)\n    print(\"EXPERIMENT SUMMARY\")\n    print(\"#\"*80)\n    \n    for scenario in all_results:\n        print(f\"\\n{scenario}:\")\n        print(\"-\"*40)\n        \n        for threshold, result in all_results[scenario].items():\n            if result and 'results' in result:\n                # Find best classifier by macro F1\n                best_clf = None\n                best_f1 = 0\n                \n                if result['results']:\n                    for clf_name, clf_results in result['results'].items():\n                        if clf_results and clf_results['f1_macro'] > best_f1:\n                            best_f1 = clf_results['f1_macro']\n                            best_clf = clf_name\n                \n                if best_clf:\n                    print(f\"  Threshold {threshold:2d}: \"\n                          f\"Best = {best_clf:8s}, \"\n                          f\"Macro F1 = {best_f1:.4f}, \"\n                          f\"Classes = {result['config']['n_classes']:3d}, \"\n                          f\"Samples = {result['config']['n_samples']:,}\")\n    \n    # Save all results\n    all_results_file = os.path.join(OUTPUT_PATH, f'all_results_house{house_number}.pkl')\n    joblib.dump(all_results, all_results_file)\n    print(f\"\\nAll results saved to: {all_results_file}\")\n    \n    return all_results\n\n# ===================== MAIN EXECUTION =====================\n\nif __name__ == \"__main__\":\n    print(\"=\"*80)\n    print(\"NILM CLASSIFICATION - CORRECTED REPLICATION\")\n    print(\"=\"*80)\n    \n    # Step 1: Analyze dataset structure\n    analyze_dataset_structure(DATA_PATH)\n    \n    # Step 2: Run experiment for House 2\n    results = run_house_experiment(house_number=2, sample_size=100000)\n    \n    print(f\"\\nOutput files saved to: {OUTPUT_PATH}\")\n    print(\"\\nGenerated files:\")\n    \n    for file in os.listdir(OUTPUT_PATH):\n        if file.endswith(('.png', '.pkl', '.csv')):\n            print(f\"  {file}\")\n    \n    print(\"\\n\" + \"=\"*80)\n    print(\"EXPERIMENT COMPLETED SUCCESSFULLY!\")\n    print(\"=\"*80)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-14T15:25:37.359464Z","iopub.execute_input":"2025-12-14T15:25:37.359919Z","iopub.status.idle":"2025-12-14T15:27:18.144899Z","shell.execute_reply.started":"2025-12-14T15:25:37.359901Z","shell.execute_reply":"2025-12-14T15:27:18.144040Z"}},"outputs":[{"name":"stdout","text":"================================================================================\nNILM CLASSIFICATION - CORRECTED REPLICATION\n================================================================================\n\n================================================================================\nREDD DATASET STRUCTURE ANALYSIS\n================================================================================\nHouses found: [1, 2, 3, 4, 5, 6]\n\n========================================\nANALYZING HOUSE 1\n========================================\n  Found 11 files\n\n  First file: redd_house1_0.csv\n  Shape: (23302, 8)\n  Columns: ['Unnamed: 0', 'dish washer', 'electric space heater', 'electric stove', 'fridge', 'microwave', 'washer dryer', 'main']\n  Appliance columns (6): ['dish washer', 'electric space heater', 'electric stove', 'fridge', 'microwave', 'washer dryer']\n\n  Data sample (first 5 rows):\n                                0          1          2          3          4\nUnnamed: 0               0.000000   1.000000   2.000000   3.000000   4.000000\ndish washer              0.000000   0.000000   0.000000   0.000000   0.000000\nelectric space heater    0.000000   0.000000   0.000000   0.000000   0.000000\nelectric stove           0.000000   0.000000   0.000000   0.000000   0.000000\nfridge                   6.000000   6.000000   6.000000   6.000000   6.000000\nmicrowave                4.000000   4.000000   4.000000   4.000000   4.000000\nwasher dryer             0.000000   0.000000   0.000000   0.000000   0.000000\nmain                   103.790001  99.630005  99.169998  99.709999  98.919998\n\n========================================\nANALYZING HOUSE 2\n========================================\n  Found 7 files\n\n  First file: redd_house2_0.csv\n  Shape: (34429, 8)\n  Columns: ['Unnamed: 0', 'dish washer', 'electric stove', 'fridge', 'microwave', 'washer dryer', 'waste disposal unit', 'main']\n  Appliance columns (6): ['dish washer', 'electric stove', 'fridge', 'microwave', 'washer dryer', 'waste disposal unit']\n\n  Data sample (first 5 rows):\n                              0           1           2           3       4\nUnnamed: 0             0.000000    1.000000    2.000000    3.000000    4.00\ndish washer            0.000000    0.000000    0.000000    1.000000    0.00\nelectric stove         0.000000    0.000000    0.000000    0.000000    1.00\nfridge               158.000000  160.000000  160.000000  158.000000  155.00\nmicrowave              5.000000    5.000000    5.000000    5.000000    5.00\nwasher dryer           4.000000    4.000000    4.000000    4.000000    4.00\nwaste disposal unit    0.000000    0.000000    0.000000    0.000000    0.00\nmain                 272.279999  272.619995  272.809998  272.529999  271.75\n\n========================================\nANALYZING HOUSE 3\n========================================\n  Found 6 files\n\n  First file: redd_house3_0.csv\n  Shape: (35491, 9)\n  Columns: ['Unnamed: 0', 'CE appliance', 'dish washer', 'electric furnace', 'fridge', 'microwave', 'washer dryer', 'waste disposal unit', 'main']\n  Appliance columns (7): ['CE appliance', 'dish washer', 'electric furnace', 'fridge', 'microwave', 'washer dryer', 'waste disposal unit']\n\n  Data sample (first 5 rows):\n                              0           1           2           3  \\\nUnnamed: 0             0.000000    1.000000    2.000000    3.000000   \nCE appliance          79.000000   89.000000   78.000000   89.000000   \ndish washer            1.000000    1.000000    1.000000    1.000000   \nelectric furnace       5.000000    5.000000    5.000000    5.000000   \nfridge               133.000000  130.000000  133.000000  133.000000   \nmicrowave              2.000000    2.000000    2.000000    2.000000   \nwasher dryer           0.000000    0.000000    0.000000    0.000000   \nwaste disposal unit    0.000000    0.000000    0.000000    0.000000   \nmain                 258.070007  257.160004  257.140015  256.619995   \n\n                              4  \nUnnamed: 0             4.000000  \nCE appliance          72.000000  \ndish washer            1.000000  \nelectric furnace       5.000000  \nfridge               130.000000  \nmicrowave              2.000000  \nwasher dryer           0.000000  \nwaste disposal unit    0.000000  \nmain                 255.809998  \n\n================================================================================\nRUNNING EXPERIMENT FOR HOUSE 2\n================================================================================\n\n============================================================\nConfiguration: With_Windowing, Threshold=5\n============================================================\n\n################################################################################\nEXPERIMENT: House 2, Threshold=5, Windowing=ON\n################################################################################\nDiscovered 6 appliances: ['dish_washer', 'electric_stove', 'fridge', 'microwave', 'washer_dryer', 'waste_disposal_unit']\nFound 7 files for house 2\n","output_type":"stream"},{"name":"stderr","text":"Loading CSV files: 100%|██████████| 7/7 [00:00<00:00, 23.68it/s]\n","output_type":"stream"},{"name":"stdout","text":"Note: Using 100,000 samples out of 292,063\nLoaded 100,000 samples\nAvailable columns: ['unnamed:_0', 'dish_washer', 'electric_stove', 'fridge', 'microwave', 'washer_dryer', 'waste_disposal_unit', 'main']\n\n================================================================================\nApplying Power Windowing (Corrected Implementation)\n================================================================================\n\nAppliance            Window (W)      Before ON  After ON   Changed    % ON Before  % ON After  \n------------------------------------------------------------------------------------------\ndish_washer          30-1200         9,898      1,353      8,545      9.9          1.4         \nelectric_stove       1000-1500       48,019     0          48,019     48.0         0.0         \nfridge               175-500         99,997     3,864      96,133     100.0        3.9         \nmicrowave            20-1650         100,000    15,980     84,020     100.0        16.0        \nwasher_dryer         250-700         98,684     0          98,684     98.7         0.0         \nwaste_disposal_unit  0-100           1,735      99,994     -98,259    1.7          100.0       \n\nThresholding Analysis (Threshold = 5):\nTotal samples: 100,000\nUnique combinations before thresholding: 8\nUnique combinations after thresholding: 7\nSamples after thresholding: 99,999 (100.0%)\nRemoved samples: 1\n\nTop 10 appliance combinations:\n  000001 : dis:0|ele:0|fri:0|mic:0|was:0|was:1 :  79,487 occurrences\n  000101 : dis:0|ele:0|fri:0|mic:1|was:0|was:1 :  15,316 occurrences\n  001001 : dis:0|ele:0|fri:1|mic:0|was:0|was:1 :   3,174 occurrences\n  100001 : dis:1|ele:0|fri:0|mic:0|was:0|was:1 :   1,328 occurrences\n  001101 : dis:0|ele:0|fri:1|mic:1|was:0|was:1 :     664 occurrences\n  101001 : dis:1|ele:0|fri:1|mic:0|was:0|was:1 :      25 occurrences\n  000000 : dis:0|ele:0|fri:0|mic:0|was:0|was:0 :       5 occurrences\n  001000 : dis:0|ele:0|fri:1|mic:0|was:0|was:0 :       1 occurrences\n\nFinal dataset for ML:\n  Features shape: (99999, 1)\n  Labels shape: (99999,)\n  Number of classes: 7\n\n  Class distribution (top 10):\n    Class   1:  79,487 samples - 000001\n    Class   2:  15,316 samples - 000101\n    Class   3:   3,174 samples - 001001\n    Class   5:   1,328 samples - 100001\n    Class   4:     664 samples - 001101\n    Class   6:      25 samples - 101001\n    Class   0:       5 samples - 000000\n\nData split:\n  Training samples: 79,999\n  Testing samples: 20,000\n  Feature dimension: 1\n  Number of classes: 7\nInitialized 7 classifiers\n\n============================================================\nTraining and Evaluating Classifiers\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"Training classifiers:  14%|█▍        | 1/7 [00:00<00:01,  5.78it/s]","output_type":"stream"},{"name":"stdout","text":"\n✓ CART: Trained in 0.11s\n  Macro F1: 0.5539\n  Weighted F1: 0.8807\n  Accuracy: 0.8851\n","output_type":"stream"},{"name":"stderr","text":"Training classifiers:  29%|██▊       | 2/7 [00:01<00:04,  1.04it/s]","output_type":"stream"},{"name":"stdout","text":"\n✓ ET: Trained in 1.27s\n  Macro F1: 0.5563\n  Weighted F1: 0.8816\n  Accuracy: 0.8857\n","output_type":"stream"},{"name":"stderr","text":"Training classifiers:  57%|█████▋    | 4/7 [00:02<00:01,  1.60it/s]","output_type":"stream"},{"name":"stdout","text":"\n✓ KNN: Trained in 0.03s\n  Macro F1: 0.5585\n  Weighted F1: 0.8861\n  Accuracy: 0.8936\n\n✓ KNN-CB: Trained in 0.03s\n  Macro F1: 0.5504\n  Weighted F1: 0.8869\n  Accuracy: 0.8919\n","output_type":"stream"},{"name":"stderr","text":"Training classifiers:  71%|███████▏  | 5/7 [00:02<00:00,  2.27it/s]","output_type":"stream"},{"name":"stdout","text":"\n✓ LDA: Trained in 0.04s\n  Macro F1: 0.1592\n  Weighted F1: 0.7024\n  Accuracy: 0.7815\n\n✓ NB: Trained in 0.01s\n  Macro F1: 0.1603\n  Weighted F1: 0.7027\n  Accuracy: 0.7815\n","output_type":"stream"},{"name":"stderr","text":"Training classifiers: 100%|██████████| 7/7 [00:06<00:00,  1.06it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n✓ RF: Trained in 3.47s\n  Macro F1: 0.5576\n  Weighted F1: 0.8817\n  Accuracy: 0.8842\n\nResults saved to: /kaggle/working/results_House2_Th5_WindowingTrue.pkl\n\n============================================================\nConfiguration: With_Windowing, Threshold=10\n============================================================\n\n################################################################################\nEXPERIMENT: House 2, Threshold=10, Windowing=ON\n################################################################################\nDiscovered 6 appliances: ['dish_washer', 'electric_stove', 'fridge', 'microwave', 'washer_dryer', 'waste_disposal_unit']\nFound 7 files for house 2\n","output_type":"stream"},{"name":"stderr","text":"Loading CSV files: 100%|██████████| 7/7 [00:00<00:00, 39.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Note: Using 100,000 samples out of 292,063\nLoaded 100,000 samples\nAvailable columns: ['unnamed:_0', 'dish_washer', 'electric_stove', 'fridge', 'microwave', 'washer_dryer', 'waste_disposal_unit', 'main']\n\n================================================================================\nApplying Power Windowing (Corrected Implementation)\n================================================================================\n\nAppliance            Window (W)      Before ON  After ON   Changed    % ON Before  % ON After  \n------------------------------------------------------------------------------------------\ndish_washer          30-1200         9,898      1,353      8,545      9.9          1.4         \nelectric_stove       1000-1500       48,019     0          48,019     48.0         0.0         \nfridge               175-500         99,997     3,864      96,133     100.0        3.9         \nmicrowave            20-1650         100,000    15,980     84,020     100.0        16.0        \nwasher_dryer         250-700         98,684     0          98,684     98.7         0.0         \nwaste_disposal_unit  0-100           1,735      99,994     -98,259    1.7          100.0       \n\nThresholding Analysis (Threshold = 10):\nTotal samples: 100,000\nUnique combinations before thresholding: 8\nUnique combinations after thresholding: 6\nSamples after thresholding: 99,994 (100.0%)\nRemoved samples: 6\n\nTop 10 appliance combinations:\n  000001 : dis:0|ele:0|fri:0|mic:0|was:0|was:1 :  79,487 occurrences\n  000101 : dis:0|ele:0|fri:0|mic:1|was:0|was:1 :  15,316 occurrences\n  001001 : dis:0|ele:0|fri:1|mic:0|was:0|was:1 :   3,174 occurrences\n  100001 : dis:1|ele:0|fri:0|mic:0|was:0|was:1 :   1,328 occurrences\n  001101 : dis:0|ele:0|fri:1|mic:1|was:0|was:1 :     664 occurrences\n  101001 : dis:1|ele:0|fri:1|mic:0|was:0|was:1 :      25 occurrences\n  000000 : dis:0|ele:0|fri:0|mic:0|was:0|was:0 :       5 occurrences\n  001000 : dis:0|ele:0|fri:1|mic:0|was:0|was:0 :       1 occurrences\n\nFinal dataset for ML:\n  Features shape: (99994, 1)\n  Labels shape: (99994,)\n  Number of classes: 6\n\n  Class distribution (top 10):\n    Class   0:  79,487 samples - 000001\n    Class   1:  15,316 samples - 000101\n    Class   2:   3,174 samples - 001001\n    Class   4:   1,328 samples - 100001\n    Class   3:     664 samples - 001101\n    Class   5:      25 samples - 101001\n\nData split:\n  Training samples: 79,995\n  Testing samples: 19,999\n  Feature dimension: 1\n  Number of classes: 6\nInitialized 7 classifiers\n\n============================================================\nTraining and Evaluating Classifiers\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"Training classifiers:  14%|█▍        | 1/7 [00:00<00:01,  5.48it/s]","output_type":"stream"},{"name":"stdout","text":"\n✓ CART: Trained in 0.12s\n  Macro F1: 0.6456\n  Weighted F1: 0.8804\n  Accuracy: 0.8847\n","output_type":"stream"},{"name":"stderr","text":"Training classifiers:  29%|██▊       | 2/7 [00:01<00:04,  1.06it/s]","output_type":"stream"},{"name":"stdout","text":"\n✓ ET: Trained in 1.26s\n  Macro F1: 0.6477\n  Weighted F1: 0.8813\n  Accuracy: 0.8855\n","output_type":"stream"},{"name":"stderr","text":"Training classifiers:  57%|█████▋    | 4/7 [00:02<00:01,  1.61it/s]","output_type":"stream"},{"name":"stdout","text":"\n✓ KNN: Trained in 0.03s\n  Macro F1: 0.6525\n  Weighted F1: 0.8867\n  Accuracy: 0.8941\n\n✓ KNN-CB: Trained in 0.03s\n  Macro F1: 0.6416\n  Weighted F1: 0.8865\n  Accuracy: 0.8913\n","output_type":"stream"},{"name":"stderr","text":"Training classifiers:  86%|████████▌ | 6/7 [00:02<00:00,  3.02it/s]","output_type":"stream"},{"name":"stdout","text":"\n✓ LDA: Trained in 0.03s\n  Macro F1: 0.1854\n  Weighted F1: 0.7023\n  Accuracy: 0.7813\n\n✓ NB: Trained in 0.01s\n  Macro F1: 0.1868\n  Weighted F1: 0.7026\n  Accuracy: 0.7813\n","output_type":"stream"},{"name":"stderr","text":"Training classifiers: 100%|██████████| 7/7 [00:06<00:00,  1.07it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n✓ RF: Trained in 3.51s\n  Macro F1: 0.6474\n  Weighted F1: 0.8808\n  Accuracy: 0.8834\n\nResults saved to: /kaggle/working/results_House2_Th10_WindowingTrue.pkl\n\n============================================================\nConfiguration: With_Windowing, Threshold=20\n============================================================\n\n################################################################################\nEXPERIMENT: House 2, Threshold=20, Windowing=ON\n################################################################################\nDiscovered 6 appliances: ['dish_washer', 'electric_stove', 'fridge', 'microwave', 'washer_dryer', 'waste_disposal_unit']\nFound 7 files for house 2\n","output_type":"stream"},{"name":"stderr","text":"Loading CSV files: 100%|██████████| 7/7 [00:00<00:00, 40.00it/s]\n","output_type":"stream"},{"name":"stdout","text":"Note: Using 100,000 samples out of 292,063\nLoaded 100,000 samples\nAvailable columns: ['unnamed:_0', 'dish_washer', 'electric_stove', 'fridge', 'microwave', 'washer_dryer', 'waste_disposal_unit', 'main']\n\n================================================================================\nApplying Power Windowing (Corrected Implementation)\n================================================================================\n\nAppliance            Window (W)      Before ON  After ON   Changed    % ON Before  % ON After  \n------------------------------------------------------------------------------------------\ndish_washer          30-1200         9,898      1,353      8,545      9.9          1.4         \nelectric_stove       1000-1500       48,019     0          48,019     48.0         0.0         \nfridge               175-500         99,997     3,864      96,133     100.0        3.9         \nmicrowave            20-1650         100,000    15,980     84,020     100.0        16.0        \nwasher_dryer         250-700         98,684     0          98,684     98.7         0.0         \nwaste_disposal_unit  0-100           1,735      99,994     -98,259    1.7          100.0       \n\nThresholding Analysis (Threshold = 20):\nTotal samples: 100,000\nUnique combinations before thresholding: 8\nUnique combinations after thresholding: 6\nSamples after thresholding: 99,994 (100.0%)\nRemoved samples: 6\n\nTop 10 appliance combinations:\n  000001 : dis:0|ele:0|fri:0|mic:0|was:0|was:1 :  79,487 occurrences\n  000101 : dis:0|ele:0|fri:0|mic:1|was:0|was:1 :  15,316 occurrences\n  001001 : dis:0|ele:0|fri:1|mic:0|was:0|was:1 :   3,174 occurrences\n  100001 : dis:1|ele:0|fri:0|mic:0|was:0|was:1 :   1,328 occurrences\n  001101 : dis:0|ele:0|fri:1|mic:1|was:0|was:1 :     664 occurrences\n  101001 : dis:1|ele:0|fri:1|mic:0|was:0|was:1 :      25 occurrences\n  000000 : dis:0|ele:0|fri:0|mic:0|was:0|was:0 :       5 occurrences\n  001000 : dis:0|ele:0|fri:1|mic:0|was:0|was:0 :       1 occurrences\n\nFinal dataset for ML:\n  Features shape: (99994, 1)\n  Labels shape: (99994,)\n  Number of classes: 6\n\n  Class distribution (top 10):\n    Class   0:  79,487 samples - 000001\n    Class   1:  15,316 samples - 000101\n    Class   2:   3,174 samples - 001001\n    Class   4:   1,328 samples - 100001\n    Class   3:     664 samples - 001101\n    Class   5:      25 samples - 101001\n\nData split:\n  Training samples: 79,995\n  Testing samples: 19,999\n  Feature dimension: 1\n  Number of classes: 6\nInitialized 7 classifiers\n\n============================================================\nTraining and Evaluating Classifiers\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"Training classifiers:  14%|█▍        | 1/7 [00:00<00:01,  5.82it/s]","output_type":"stream"},{"name":"stdout","text":"\n✓ CART: Trained in 0.11s\n  Macro F1: 0.6456\n  Weighted F1: 0.8804\n  Accuracy: 0.8847\n","output_type":"stream"},{"name":"stderr","text":"Training classifiers:  29%|██▊       | 2/7 [00:01<00:04,  1.06it/s]","output_type":"stream"},{"name":"stdout","text":"\n✓ ET: Trained in 1.26s\n  Macro F1: 0.6477\n  Weighted F1: 0.8813\n  Accuracy: 0.8855\n","output_type":"stream"},{"name":"stderr","text":"Training classifiers:  57%|█████▋    | 4/7 [00:02<00:01,  1.62it/s]","output_type":"stream"},{"name":"stdout","text":"\n✓ KNN: Trained in 0.03s\n  Macro F1: 0.6525\n  Weighted F1: 0.8867\n  Accuracy: 0.8941\n\n✓ KNN-CB: Trained in 0.03s\n  Macro F1: 0.6416\n  Weighted F1: 0.8865\n  Accuracy: 0.8913\n","output_type":"stream"},{"name":"stderr","text":"Training classifiers:  86%|████████▌ | 6/7 [00:02<00:00,  3.03it/s]","output_type":"stream"},{"name":"stdout","text":"\n✓ LDA: Trained in 0.03s\n  Macro F1: 0.1854\n  Weighted F1: 0.7023\n  Accuracy: 0.7813\n\n✓ NB: Trained in 0.01s\n  Macro F1: 0.1868\n  Weighted F1: 0.7026\n  Accuracy: 0.7813\n","output_type":"stream"},{"name":"stderr","text":"Training classifiers: 100%|██████████| 7/7 [00:06<00:00,  1.08it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n✓ RF: Trained in 3.46s\n  Macro F1: 0.6474\n  Weighted F1: 0.8808\n  Accuracy: 0.8834\n\nResults saved to: /kaggle/working/results_House2_Th20_WindowingTrue.pkl\n\n============================================================\nConfiguration: With_Windowing, Threshold=30\n============================================================\n\n################################################################################\nEXPERIMENT: House 2, Threshold=30, Windowing=ON\n################################################################################\nDiscovered 6 appliances: ['dish_washer', 'electric_stove', 'fridge', 'microwave', 'washer_dryer', 'waste_disposal_unit']\nFound 7 files for house 2\n","output_type":"stream"},{"name":"stderr","text":"Loading CSV files: 100%|██████████| 7/7 [00:00<00:00, 38.10it/s]\n","output_type":"stream"},{"name":"stdout","text":"Note: Using 100,000 samples out of 292,063\nLoaded 100,000 samples\nAvailable columns: ['unnamed:_0', 'dish_washer', 'electric_stove', 'fridge', 'microwave', 'washer_dryer', 'waste_disposal_unit', 'main']\n\n================================================================================\nApplying Power Windowing (Corrected Implementation)\n================================================================================\n\nAppliance            Window (W)      Before ON  After ON   Changed    % ON Before  % ON After  \n------------------------------------------------------------------------------------------\ndish_washer          30-1200         9,898      1,353      8,545      9.9          1.4         \nelectric_stove       1000-1500       48,019     0          48,019     48.0         0.0         \nfridge               175-500         99,997     3,864      96,133     100.0        3.9         \nmicrowave            20-1650         100,000    15,980     84,020     100.0        16.0        \nwasher_dryer         250-700         98,684     0          98,684     98.7         0.0         \nwaste_disposal_unit  0-100           1,735      99,994     -98,259    1.7          100.0       \n\nThresholding Analysis (Threshold = 30):\nTotal samples: 100,000\nUnique combinations before thresholding: 8\nUnique combinations after thresholding: 5\nSamples after thresholding: 99,969 (100.0%)\nRemoved samples: 31\n\nTop 10 appliance combinations:\n  000001 : dis:0|ele:0|fri:0|mic:0|was:0|was:1 :  79,487 occurrences\n  000101 : dis:0|ele:0|fri:0|mic:1|was:0|was:1 :  15,316 occurrences\n  001001 : dis:0|ele:0|fri:1|mic:0|was:0|was:1 :   3,174 occurrences\n  100001 : dis:1|ele:0|fri:0|mic:0|was:0|was:1 :   1,328 occurrences\n  001101 : dis:0|ele:0|fri:1|mic:1|was:0|was:1 :     664 occurrences\n  101001 : dis:1|ele:0|fri:1|mic:0|was:0|was:1 :      25 occurrences\n  000000 : dis:0|ele:0|fri:0|mic:0|was:0|was:0 :       5 occurrences\n  001000 : dis:0|ele:0|fri:1|mic:0|was:0|was:0 :       1 occurrences\n\nFinal dataset for ML:\n  Features shape: (99969, 1)\n  Labels shape: (99969,)\n  Number of classes: 5\n\n  Class distribution (top 10):\n    Class   0:  79,487 samples - 000001\n    Class   1:  15,316 samples - 000101\n    Class   2:   3,174 samples - 001001\n    Class   4:   1,328 samples - 100001\n    Class   3:     664 samples - 001101\n\nData split:\n  Training samples: 79,975\n  Testing samples: 19,994\n  Feature dimension: 1\n  Number of classes: 5\nInitialized 7 classifiers\n\n============================================================\nTraining and Evaluating Classifiers\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"Training classifiers:  14%|█▍        | 1/7 [00:00<00:01,  5.93it/s]","output_type":"stream"},{"name":"stdout","text":"\n✓ CART: Trained in 0.11s\n  Macro F1: 0.6427\n  Weighted F1: 0.8806\n  Accuracy: 0.8849\n","output_type":"stream"},{"name":"stderr","text":"Training classifiers:  29%|██▊       | 2/7 [00:01<00:04,  1.07it/s]","output_type":"stream"},{"name":"stdout","text":"\n✓ ET: Trained in 1.26s\n  Macro F1: 0.6461\n  Weighted F1: 0.8812\n  Accuracy: 0.8853\n","output_type":"stream"},{"name":"stderr","text":"Training classifiers:  57%|█████▋    | 4/7 [00:02<00:01,  1.62it/s]","output_type":"stream"},{"name":"stdout","text":"\n✓ KNN: Trained in 0.03s\n  Macro F1: 0.6504\n  Weighted F1: 0.8865\n  Accuracy: 0.8938\n\n✓ KNN-CB: Trained in 0.03s\n  Macro F1: 0.6641\n  Weighted F1: 0.8870\n  Accuracy: 0.8918\n","output_type":"stream"},{"name":"stderr","text":"Training classifiers:  86%|████████▌ | 6/7 [00:02<00:00,  3.05it/s]","output_type":"stream"},{"name":"stdout","text":"\n✓ LDA: Trained in 0.03s\n  Macro F1: 0.2200\n  Weighted F1: 0.7023\n  Accuracy: 0.7816\n\n✓ NB: Trained in 0.01s\n  Macro F1: 0.2244\n  Weighted F1: 0.7028\n  Accuracy: 0.7815\n","output_type":"stream"},{"name":"stderr","text":"Training classifiers: 100%|██████████| 7/7 [00:06<00:00,  1.08it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n✓ RF: Trained in 3.46s\n  Macro F1: 0.6456\n  Weighted F1: 0.8810\n  Accuracy: 0.8836\n\nResults saved to: /kaggle/working/results_House2_Th30_WindowingTrue.pkl\n\n============================================================\nConfiguration: With_Windowing, Threshold=40\n============================================================\n\n################################################################################\nEXPERIMENT: House 2, Threshold=40, Windowing=ON\n################################################################################\nDiscovered 6 appliances: ['dish_washer', 'electric_stove', 'fridge', 'microwave', 'washer_dryer', 'waste_disposal_unit']\nFound 7 files for house 2\n","output_type":"stream"},{"name":"stderr","text":"Loading CSV files: 100%|██████████| 7/7 [00:00<00:00, 40.78it/s]\n","output_type":"stream"},{"name":"stdout","text":"Note: Using 100,000 samples out of 292,063\nLoaded 100,000 samples\nAvailable columns: ['unnamed:_0', 'dish_washer', 'electric_stove', 'fridge', 'microwave', 'washer_dryer', 'waste_disposal_unit', 'main']\n\n================================================================================\nApplying Power Windowing (Corrected Implementation)\n================================================================================\n\nAppliance            Window (W)      Before ON  After ON   Changed    % ON Before  % ON After  \n------------------------------------------------------------------------------------------\ndish_washer          30-1200         9,898      1,353      8,545      9.9          1.4         \nelectric_stove       1000-1500       48,019     0          48,019     48.0         0.0         \nfridge               175-500         99,997     3,864      96,133     100.0        3.9         \nmicrowave            20-1650         100,000    15,980     84,020     100.0        16.0        \nwasher_dryer         250-700         98,684     0          98,684     98.7         0.0         \nwaste_disposal_unit  0-100           1,735      99,994     -98,259    1.7          100.0       \n\nThresholding Analysis (Threshold = 40):\nTotal samples: 100,000\nUnique combinations before thresholding: 8\nUnique combinations after thresholding: 5\nSamples after thresholding: 99,969 (100.0%)\nRemoved samples: 31\n\nTop 10 appliance combinations:\n  000001 : dis:0|ele:0|fri:0|mic:0|was:0|was:1 :  79,487 occurrences\n  000101 : dis:0|ele:0|fri:0|mic:1|was:0|was:1 :  15,316 occurrences\n  001001 : dis:0|ele:0|fri:1|mic:0|was:0|was:1 :   3,174 occurrences\n  100001 : dis:1|ele:0|fri:0|mic:0|was:0|was:1 :   1,328 occurrences\n  001101 : dis:0|ele:0|fri:1|mic:1|was:0|was:1 :     664 occurrences\n  101001 : dis:1|ele:0|fri:1|mic:0|was:0|was:1 :      25 occurrences\n  000000 : dis:0|ele:0|fri:0|mic:0|was:0|was:0 :       5 occurrences\n  001000 : dis:0|ele:0|fri:1|mic:0|was:0|was:0 :       1 occurrences\n\nFinal dataset for ML:\n  Features shape: (99969, 1)\n  Labels shape: (99969,)\n  Number of classes: 5\n\n  Class distribution (top 10):\n    Class   0:  79,487 samples - 000001\n    Class   1:  15,316 samples - 000101\n    Class   2:   3,174 samples - 001001\n    Class   4:   1,328 samples - 100001\n    Class   3:     664 samples - 001101\n\nData split:\n  Training samples: 79,975\n  Testing samples: 19,994\n  Feature dimension: 1\n  Number of classes: 5\nInitialized 7 classifiers\n\n============================================================\nTraining and Evaluating Classifiers\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"Training classifiers:  14%|█▍        | 1/7 [00:00<00:01,  5.81it/s]","output_type":"stream"},{"name":"stdout","text":"\n✓ CART: Trained in 0.11s\n  Macro F1: 0.6427\n  Weighted F1: 0.8806\n  Accuracy: 0.8849\n","output_type":"stream"},{"name":"stderr","text":"Training classifiers:  29%|██▊       | 2/7 [00:01<00:04,  1.06it/s]","output_type":"stream"},{"name":"stdout","text":"\n✓ ET: Trained in 1.26s\n  Macro F1: 0.6461\n  Weighted F1: 0.8812\n  Accuracy: 0.8853\n","output_type":"stream"},{"name":"stderr","text":"Training classifiers:  57%|█████▋    | 4/7 [00:02<00:01,  1.60it/s]","output_type":"stream"},{"name":"stdout","text":"\n✓ KNN: Trained in 0.03s\n  Macro F1: 0.6504\n  Weighted F1: 0.8865\n  Accuracy: 0.8938\n\n✓ KNN-CB: Trained in 0.03s\n  Macro F1: 0.6641\n  Weighted F1: 0.8870\n  Accuracy: 0.8918\n","output_type":"stream"},{"name":"stderr","text":"Training classifiers:  86%|████████▌ | 6/7 [00:02<00:00,  3.01it/s]","output_type":"stream"},{"name":"stdout","text":"\n✓ LDA: Trained in 0.03s\n  Macro F1: 0.2200\n  Weighted F1: 0.7023\n  Accuracy: 0.7816\n\n✓ NB: Trained in 0.01s\n  Macro F1: 0.2244\n  Weighted F1: 0.7028\n  Accuracy: 0.7815\n","output_type":"stream"},{"name":"stderr","text":"Training classifiers: 100%|██████████| 7/7 [00:06<00:00,  1.07it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n✓ RF: Trained in 3.45s\n  Macro F1: 0.6456\n  Weighted F1: 0.8810\n  Accuracy: 0.8836\n\nResults saved to: /kaggle/working/results_House2_Th40_WindowingTrue.pkl\n\n============================================================\nConfiguration: With_Windowing, Threshold=50\n============================================================\n\n################################################################################\nEXPERIMENT: House 2, Threshold=50, Windowing=ON\n################################################################################\nDiscovered 6 appliances: ['dish_washer', 'electric_stove', 'fridge', 'microwave', 'washer_dryer', 'waste_disposal_unit']\nFound 7 files for house 2\n","output_type":"stream"},{"name":"stderr","text":"Loading CSV files: 100%|██████████| 7/7 [00:00<00:00, 38.82it/s]\n","output_type":"stream"},{"name":"stdout","text":"Note: Using 100,000 samples out of 292,063\nLoaded 100,000 samples\nAvailable columns: ['unnamed:_0', 'dish_washer', 'electric_stove', 'fridge', 'microwave', 'washer_dryer', 'waste_disposal_unit', 'main']\n\n================================================================================\nApplying Power Windowing (Corrected Implementation)\n================================================================================\n\nAppliance            Window (W)      Before ON  After ON   Changed    % ON Before  % ON After  \n------------------------------------------------------------------------------------------\ndish_washer          30-1200         9,898      1,353      8,545      9.9          1.4         \nelectric_stove       1000-1500       48,019     0          48,019     48.0         0.0         \nfridge               175-500         99,997     3,864      96,133     100.0        3.9         \nmicrowave            20-1650         100,000    15,980     84,020     100.0        16.0        \nwasher_dryer         250-700         98,684     0          98,684     98.7         0.0         \nwaste_disposal_unit  0-100           1,735      99,994     -98,259    1.7          100.0       \n\nThresholding Analysis (Threshold = 50):\nTotal samples: 100,000\nUnique combinations before thresholding: 8\nUnique combinations after thresholding: 5\nSamples after thresholding: 99,969 (100.0%)\nRemoved samples: 31\n\nTop 10 appliance combinations:\n  000001 : dis:0|ele:0|fri:0|mic:0|was:0|was:1 :  79,487 occurrences\n  000101 : dis:0|ele:0|fri:0|mic:1|was:0|was:1 :  15,316 occurrences\n  001001 : dis:0|ele:0|fri:1|mic:0|was:0|was:1 :   3,174 occurrences\n  100001 : dis:1|ele:0|fri:0|mic:0|was:0|was:1 :   1,328 occurrences\n  001101 : dis:0|ele:0|fri:1|mic:1|was:0|was:1 :     664 occurrences\n  101001 : dis:1|ele:0|fri:1|mic:0|was:0|was:1 :      25 occurrences\n  000000 : dis:0|ele:0|fri:0|mic:0|was:0|was:0 :       5 occurrences\n  001000 : dis:0|ele:0|fri:1|mic:0|was:0|was:0 :       1 occurrences\n\nFinal dataset for ML:\n  Features shape: (99969, 1)\n  Labels shape: (99969,)\n  Number of classes: 5\n\n  Class distribution (top 10):\n    Class   0:  79,487 samples - 000001\n    Class   1:  15,316 samples - 000101\n    Class   2:   3,174 samples - 001001\n    Class   4:   1,328 samples - 100001\n    Class   3:     664 samples - 001101\n\nData split:\n  Training samples: 79,975\n  Testing samples: 19,994\n  Feature dimension: 1\n  Number of classes: 5\nInitialized 7 classifiers\n\n============================================================\nTraining and Evaluating Classifiers\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"Training classifiers:  14%|█▍        | 1/7 [00:00<00:01,  5.93it/s]","output_type":"stream"},{"name":"stdout","text":"\n✓ CART: Trained in 0.11s\n  Macro F1: 0.6427\n  Weighted F1: 0.8806\n  Accuracy: 0.8849\n","output_type":"stream"},{"name":"stderr","text":"Training classifiers:  29%|██▊       | 2/7 [00:01<00:04,  1.09it/s]","output_type":"stream"},{"name":"stdout","text":"\n✓ ET: Trained in 1.22s\n  Macro F1: 0.6461\n  Weighted F1: 0.8812\n  Accuracy: 0.8853\n","output_type":"stream"},{"name":"stderr","text":"Training classifiers:  57%|█████▋    | 4/7 [00:02<00:01,  1.69it/s]","output_type":"stream"},{"name":"stdout","text":"\n✓ KNN: Trained in 0.03s\n  Macro F1: 0.6504\n  Weighted F1: 0.8865\n  Accuracy: 0.8938\n\n✓ KNN-CB: Trained in 0.03s\n  Macro F1: 0.6641\n  Weighted F1: 0.8870\n  Accuracy: 0.8918\n","output_type":"stream"},{"name":"stderr","text":"Training classifiers:  86%|████████▌ | 6/7 [00:02<00:00,  3.16it/s]","output_type":"stream"},{"name":"stdout","text":"\n✓ LDA: Trained in 0.03s\n  Macro F1: 0.2200\n  Weighted F1: 0.7023\n  Accuracy: 0.7816\n\n✓ NB: Trained in 0.01s\n  Macro F1: 0.2244\n  Weighted F1: 0.7028\n  Accuracy: 0.7815\n","output_type":"stream"},{"name":"stderr","text":"Training classifiers: 100%|██████████| 7/7 [00:06<00:00,  1.09it/s]\n","output_type":"stream"},{"name":"stdout","text":"\n✓ RF: Trained in 3.51s\n  Macro F1: 0.6456\n  Weighted F1: 0.8810\n  Accuracy: 0.8836\n\nResults saved to: /kaggle/working/results_House2_Th50_WindowingTrue.pkl\n\n============================================================\nConfiguration: Without_Windowing, Threshold=5\n============================================================\n\n################################################################################\nEXPERIMENT: House 2, Threshold=5, Windowing=OFF\n################################################################################\nDiscovered 6 appliances: ['dish_washer', 'electric_stove', 'fridge', 'microwave', 'washer_dryer', 'waste_disposal_unit']\nFound 7 files for house 2\n","output_type":"stream"},{"name":"stderr","text":"Loading CSV files: 100%|██████████| 7/7 [00:00<00:00, 39.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Note: Using 100,000 samples out of 292,063\nLoaded 100,000 samples\nAvailable columns: ['unnamed:_0', 'dish_washer', 'electric_stove', 'fridge', 'microwave', 'washer_dryer', 'waste_disposal_unit', 'main']\n\nUsing binary labeling without power windowing (paper baseline)\n\nThresholding Analysis (Threshold = 5):\nTotal samples: 100,000\nUnique combinations before thresholding: 14\nUnique combinations after thresholding: 10\nSamples after thresholding: 99,992 (100.0%)\nRemoved samples: 8\n\nTop 10 appliance combinations:\n  001110 : dis:0|ele:0|fri:1|mic:1|was:1|was:0 :  45,680 occurrences\n  011110 : dis:0|ele:1|fri:1|mic:1|was:1|was:0 :  43,169 occurrences\n  111110 : dis:1|ele:1|fri:1|mic:1|was:1|was:0 :   4,080 occurrences\n  101110 : dis:1|ele:0|fri:1|mic:1|was:1|was:0 :   4,018 occurrences\n  101111 : dis:1|ele:0|fri:1|mic:1|was:1|was:1 :   1,200 occurrences\n  001100 : dis:0|ele:0|fri:1|mic:1|was:0|was:0 :   1,029 occurrences\n  111111 : dis:1|ele:1|fri:1|mic:1|was:1|was:1 :     530 occurrences\n  011100 : dis:0|ele:1|fri:1|mic:1|was:0|was:0 :     216 occurrences\n  101100 : dis:1|ele:0|fri:1|mic:1|was:0|was:0 :      52 occurrences\n  111100 : dis:1|ele:1|fri:1|mic:1|was:0|was:0 :      18 occurrences\n\nFinal dataset for ML:\n  Features shape: (99992, 1)\n  Labels shape: (99992,)\n  Number of classes: 10\n\n  Class distribution (top 10):\n    Class   1:  45,680 samples - 001110\n    Class   3:  43,169 samples - 011110\n    Class   8:   4,080 samples - 111110\n    Class   5:   4,018 samples - 101110\n    Class   6:   1,200 samples - 101111\n    Class   0:   1,029 samples - 001100\n    Class   9:     530 samples - 111111\n    Class   2:     216 samples - 011100\n    Class   4:      52 samples - 101100\n    Class   7:      18 samples - 111100\n\nData split:\n  Training samples: 79,993\n  Testing samples: 19,999\n  Feature dimension: 1\n  Number of classes: 10\nInitialized 7 classifiers\n\n============================================================\nTraining and Evaluating Classifiers\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"Training classifiers:  14%|█▍        | 1/7 [00:00<00:01,  4.88it/s]","output_type":"stream"},{"name":"stdout","text":"\n✓ CART: Trained in 0.15s\n  Macro F1: 0.3359\n  Weighted F1: 0.7336\n  Accuracy: 0.7503\n","output_type":"stream"},{"name":"stderr","text":"Training classifiers:  29%|██▊       | 2/7 [00:02<00:06,  1.24s/it]","output_type":"stream"},{"name":"stdout","text":"\n✓ ET: Trained in 1.68s\n  Macro F1: 0.3582\n  Weighted F1: 0.7350\n  Accuracy: 0.7517\n","output_type":"stream"},{"name":"stderr","text":"Training classifiers:  57%|█████▋    | 4/7 [00:03<00:02,  1.40it/s]","output_type":"stream"},{"name":"stdout","text":"\n✓ KNN: Trained in 0.03s\n  Macro F1: 0.3124\n  Weighted F1: 0.7257\n  Accuracy: 0.7504\n\n✓ KNN-CB: Trained in 0.03s\n  Macro F1: 0.3763\n  Weighted F1: 0.7424\n  Accuracy: 0.7598\n","output_type":"stream"},{"name":"stderr","text":"Training classifiers:  86%|████████▌ | 6/7 [00:03<00:00,  2.70it/s]","output_type":"stream"},{"name":"stdout","text":"\n✓ LDA: Trained in 0.03s\n  Macro F1: 0.1902\n  Weighted F1: 0.7125\n  Accuracy: 0.7477\n\n✓ NB: Trained in 0.01s\n  Macro F1: 0.1888\n  Weighted F1: 0.7119\n  Accuracy: 0.7465\n","output_type":"stream"},{"name":"stderr","text":"Training classifiers: 100%|██████████| 7/7 [00:08<00:00,  1.16s/it]\n","output_type":"stream"},{"name":"stdout","text":"\n✓ RF: Trained in 4.49s\n  Macro F1: 0.3373\n  Weighted F1: 0.7347\n  Accuracy: 0.7507\n\nResults saved to: /kaggle/working/results_House2_Th5_WindowingFalse.pkl\n\n============================================================\nConfiguration: Without_Windowing, Threshold=10\n============================================================\n\n################################################################################\nEXPERIMENT: House 2, Threshold=10, Windowing=OFF\n################################################################################\nDiscovered 6 appliances: ['dish_washer', 'electric_stove', 'fridge', 'microwave', 'washer_dryer', 'waste_disposal_unit']\nFound 7 files for house 2\n","output_type":"stream"},{"name":"stderr","text":"Loading CSV files: 100%|██████████| 7/7 [00:00<00:00, 39.53it/s]\n","output_type":"stream"},{"name":"stdout","text":"Note: Using 100,000 samples out of 292,063\nLoaded 100,000 samples\nAvailable columns: ['unnamed:_0', 'dish_washer', 'electric_stove', 'fridge', 'microwave', 'washer_dryer', 'waste_disposal_unit', 'main']\n\nUsing binary labeling without power windowing (paper baseline)\n\nThresholding Analysis (Threshold = 10):\nTotal samples: 100,000\nUnique combinations before thresholding: 14\nUnique combinations after thresholding: 10\nSamples after thresholding: 99,992 (100.0%)\nRemoved samples: 8\n\nTop 10 appliance combinations:\n  001110 : dis:0|ele:0|fri:1|mic:1|was:1|was:0 :  45,680 occurrences\n  011110 : dis:0|ele:1|fri:1|mic:1|was:1|was:0 :  43,169 occurrences\n  111110 : dis:1|ele:1|fri:1|mic:1|was:1|was:0 :   4,080 occurrences\n  101110 : dis:1|ele:0|fri:1|mic:1|was:1|was:0 :   4,018 occurrences\n  101111 : dis:1|ele:0|fri:1|mic:1|was:1|was:1 :   1,200 occurrences\n  001100 : dis:0|ele:0|fri:1|mic:1|was:0|was:0 :   1,029 occurrences\n  111111 : dis:1|ele:1|fri:1|mic:1|was:1|was:1 :     530 occurrences\n  011100 : dis:0|ele:1|fri:1|mic:1|was:0|was:0 :     216 occurrences\n  101100 : dis:1|ele:0|fri:1|mic:1|was:0|was:0 :      52 occurrences\n  111100 : dis:1|ele:1|fri:1|mic:1|was:0|was:0 :      18 occurrences\n\nFinal dataset for ML:\n  Features shape: (99992, 1)\n  Labels shape: (99992,)\n  Number of classes: 10\n\n  Class distribution (top 10):\n    Class   1:  45,680 samples - 001110\n    Class   3:  43,169 samples - 011110\n    Class   8:   4,080 samples - 111110\n    Class   5:   4,018 samples - 101110\n    Class   6:   1,200 samples - 101111\n    Class   0:   1,029 samples - 001100\n    Class   9:     530 samples - 111111\n    Class   2:     216 samples - 011100\n    Class   4:      52 samples - 101100\n    Class   7:      18 samples - 111100\n\nData split:\n  Training samples: 79,993\n  Testing samples: 19,999\n  Feature dimension: 1\n  Number of classes: 10\nInitialized 7 classifiers\n\n============================================================\nTraining and Evaluating Classifiers\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"Training classifiers:  14%|█▍        | 1/7 [00:00<00:01,  4.87it/s]","output_type":"stream"},{"name":"stdout","text":"\n✓ CART: Trained in 0.15s\n  Macro F1: 0.3359\n  Weighted F1: 0.7336\n  Accuracy: 0.7503\n","output_type":"stream"},{"name":"stderr","text":"Training classifiers:  29%|██▊       | 2/7 [00:02<00:06,  1.25s/it]","output_type":"stream"},{"name":"stdout","text":"\n✓ ET: Trained in 1.71s\n  Macro F1: 0.3582\n  Weighted F1: 0.7350\n  Accuracy: 0.7517\n","output_type":"stream"},{"name":"stderr","text":"Training classifiers:  57%|█████▋    | 4/7 [00:03<00:02,  1.39it/s]","output_type":"stream"},{"name":"stdout","text":"\n✓ KNN: Trained in 0.03s\n  Macro F1: 0.3124\n  Weighted F1: 0.7257\n  Accuracy: 0.7504\n\n✓ KNN-CB: Trained in 0.03s\n  Macro F1: 0.3763\n  Weighted F1: 0.7424\n  Accuracy: 0.7598\n","output_type":"stream"},{"name":"stderr","text":"Training classifiers:  86%|████████▌ | 6/7 [00:03<00:00,  2.69it/s]","output_type":"stream"},{"name":"stdout","text":"\n✓ LDA: Trained in 0.03s\n  Macro F1: 0.1902\n  Weighted F1: 0.7125\n  Accuracy: 0.7477\n\n✓ NB: Trained in 0.01s\n  Macro F1: 0.1888\n  Weighted F1: 0.7119\n  Accuracy: 0.7465\n","output_type":"stream"},{"name":"stderr","text":"Training classifiers: 100%|██████████| 7/7 [00:08<00:00,  1.15s/it]\n","output_type":"stream"},{"name":"stdout","text":"\n✓ RF: Trained in 4.45s\n  Macro F1: 0.3373\n  Weighted F1: 0.7347\n  Accuracy: 0.7507\n\nResults saved to: /kaggle/working/results_House2_Th10_WindowingFalse.pkl\n\n============================================================\nConfiguration: Without_Windowing, Threshold=20\n============================================================\n\n################################################################################\nEXPERIMENT: House 2, Threshold=20, Windowing=OFF\n################################################################################\nDiscovered 6 appliances: ['dish_washer', 'electric_stove', 'fridge', 'microwave', 'washer_dryer', 'waste_disposal_unit']\nFound 7 files for house 2\n","output_type":"stream"},{"name":"stderr","text":"Loading CSV files: 100%|██████████| 7/7 [00:00<00:00, 39.34it/s]\n","output_type":"stream"},{"name":"stdout","text":"Note: Using 100,000 samples out of 292,063\nLoaded 100,000 samples\nAvailable columns: ['unnamed:_0', 'dish_washer', 'electric_stove', 'fridge', 'microwave', 'washer_dryer', 'waste_disposal_unit', 'main']\n\nUsing binary labeling without power windowing (paper baseline)\n\nThresholding Analysis (Threshold = 20):\nTotal samples: 100,000\nUnique combinations before thresholding: 14\nUnique combinations after thresholding: 9\nSamples after thresholding: 99,974 (100.0%)\nRemoved samples: 26\n\nTop 10 appliance combinations:\n  001110 : dis:0|ele:0|fri:1|mic:1|was:1|was:0 :  45,680 occurrences\n  011110 : dis:0|ele:1|fri:1|mic:1|was:1|was:0 :  43,169 occurrences\n  111110 : dis:1|ele:1|fri:1|mic:1|was:1|was:0 :   4,080 occurrences\n  101110 : dis:1|ele:0|fri:1|mic:1|was:1|was:0 :   4,018 occurrences\n  101111 : dis:1|ele:0|fri:1|mic:1|was:1|was:1 :   1,200 occurrences\n  001100 : dis:0|ele:0|fri:1|mic:1|was:0|was:0 :   1,029 occurrences\n  111111 : dis:1|ele:1|fri:1|mic:1|was:1|was:1 :     530 occurrences\n  011100 : dis:0|ele:1|fri:1|mic:1|was:0|was:0 :     216 occurrences\n  101100 : dis:1|ele:0|fri:1|mic:1|was:0|was:0 :      52 occurrences\n  111100 : dis:1|ele:1|fri:1|mic:1|was:0|was:0 :      18 occurrences\n\nFinal dataset for ML:\n  Features shape: (99974, 1)\n  Labels shape: (99974,)\n  Number of classes: 9\n\n  Class distribution (top 10):\n    Class   1:  45,680 samples - 001110\n    Class   3:  43,169 samples - 011110\n    Class   7:   4,080 samples - 111110\n    Class   5:   4,018 samples - 101110\n    Class   6:   1,200 samples - 101111\n    Class   0:   1,029 samples - 001100\n    Class   8:     530 samples - 111111\n    Class   2:     216 samples - 011100\n    Class   4:      52 samples - 101100\n\nData split:\n  Training samples: 79,979\n  Testing samples: 19,995\n  Feature dimension: 1\n  Number of classes: 9\nInitialized 7 classifiers\n\n============================================================\nTraining and Evaluating Classifiers\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"Training classifiers:  14%|█▍        | 1/7 [00:00<00:01,  4.52it/s]","output_type":"stream"},{"name":"stdout","text":"\n✓ CART: Trained in 0.16s\n  Macro F1: 0.3735\n  Weighted F1: 0.7338\n  Accuracy: 0.7503\n","output_type":"stream"},{"name":"stderr","text":"Training classifiers:  29%|██▊       | 2/7 [00:02<00:06,  1.24s/it]","output_type":"stream"},{"name":"stdout","text":"\n✓ ET: Trained in 1.67s\n  Macro F1: 0.3789\n  Weighted F1: 0.7355\n  Accuracy: 0.7521\n","output_type":"stream"},{"name":"stderr","text":"Training classifiers:  57%|█████▋    | 4/7 [00:03<00:02,  1.40it/s]","output_type":"stream"},{"name":"stdout","text":"\n✓ KNN: Trained in 0.03s\n  Macro F1: 0.3434\n  Weighted F1: 0.7279\n  Accuracy: 0.7512\n\n✓ KNN-CB: Trained in 0.03s\n  Macro F1: 0.4222\n  Weighted F1: 0.7431\n  Accuracy: 0.7604\n","output_type":"stream"},{"name":"stderr","text":"Training classifiers:  86%|████████▌ | 6/7 [00:03<00:00,  2.71it/s]","output_type":"stream"},{"name":"stdout","text":"\n✓ LDA: Trained in 0.03s\n  Macro F1: 0.2113\n  Weighted F1: 0.7127\n  Accuracy: 0.7478\n\n✓ NB: Trained in 0.01s\n  Macro F1: 0.2098\n  Weighted F1: 0.7122\n  Accuracy: 0.7467\n","output_type":"stream"},{"name":"stderr","text":"Training classifiers: 100%|██████████| 7/7 [00:07<00:00,  1.14s/it]\n","output_type":"stream"},{"name":"stdout","text":"\n✓ RF: Trained in 4.41s\n  Macro F1: 0.3689\n  Weighted F1: 0.7339\n  Accuracy: 0.7497\n\nResults saved to: /kaggle/working/results_House2_Th20_WindowingFalse.pkl\n\n============================================================\nConfiguration: Without_Windowing, Threshold=30\n============================================================\n\n################################################################################\nEXPERIMENT: House 2, Threshold=30, Windowing=OFF\n################################################################################\nDiscovered 6 appliances: ['dish_washer', 'electric_stove', 'fridge', 'microwave', 'washer_dryer', 'waste_disposal_unit']\nFound 7 files for house 2\n","output_type":"stream"},{"name":"stderr","text":"Loading CSV files: 100%|██████████| 7/7 [00:00<00:00, 40.22it/s]\n","output_type":"stream"},{"name":"stdout","text":"Note: Using 100,000 samples out of 292,063\nLoaded 100,000 samples\nAvailable columns: ['unnamed:_0', 'dish_washer', 'electric_stove', 'fridge', 'microwave', 'washer_dryer', 'waste_disposal_unit', 'main']\n\nUsing binary labeling without power windowing (paper baseline)\n\nThresholding Analysis (Threshold = 30):\nTotal samples: 100,000\nUnique combinations before thresholding: 14\nUnique combinations after thresholding: 9\nSamples after thresholding: 99,974 (100.0%)\nRemoved samples: 26\n\nTop 10 appliance combinations:\n  001110 : dis:0|ele:0|fri:1|mic:1|was:1|was:0 :  45,680 occurrences\n  011110 : dis:0|ele:1|fri:1|mic:1|was:1|was:0 :  43,169 occurrences\n  111110 : dis:1|ele:1|fri:1|mic:1|was:1|was:0 :   4,080 occurrences\n  101110 : dis:1|ele:0|fri:1|mic:1|was:1|was:0 :   4,018 occurrences\n  101111 : dis:1|ele:0|fri:1|mic:1|was:1|was:1 :   1,200 occurrences\n  001100 : dis:0|ele:0|fri:1|mic:1|was:0|was:0 :   1,029 occurrences\n  111111 : dis:1|ele:1|fri:1|mic:1|was:1|was:1 :     530 occurrences\n  011100 : dis:0|ele:1|fri:1|mic:1|was:0|was:0 :     216 occurrences\n  101100 : dis:1|ele:0|fri:1|mic:1|was:0|was:0 :      52 occurrences\n  111100 : dis:1|ele:1|fri:1|mic:1|was:0|was:0 :      18 occurrences\n\nFinal dataset for ML:\n  Features shape: (99974, 1)\n  Labels shape: (99974,)\n  Number of classes: 9\n\n  Class distribution (top 10):\n    Class   1:  45,680 samples - 001110\n    Class   3:  43,169 samples - 011110\n    Class   7:   4,080 samples - 111110\n    Class   5:   4,018 samples - 101110\n    Class   6:   1,200 samples - 101111\n    Class   0:   1,029 samples - 001100\n    Class   8:     530 samples - 111111\n    Class   2:     216 samples - 011100\n    Class   4:      52 samples - 101100\n\nData split:\n  Training samples: 79,979\n  Testing samples: 19,995\n  Feature dimension: 1\n  Number of classes: 9\nInitialized 7 classifiers\n\n============================================================\nTraining and Evaluating Classifiers\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"Training classifiers:  14%|█▍        | 1/7 [00:00<00:01,  4.97it/s]","output_type":"stream"},{"name":"stdout","text":"\n✓ CART: Trained in 0.14s\n  Macro F1: 0.3735\n  Weighted F1: 0.7338\n  Accuracy: 0.7503\n","output_type":"stream"},{"name":"stderr","text":"Training classifiers:  29%|██▊       | 2/7 [00:02<00:06,  1.25s/it]","output_type":"stream"},{"name":"stdout","text":"\n✓ ET: Trained in 1.69s\n  Macro F1: 0.3789\n  Weighted F1: 0.7355\n  Accuracy: 0.7521\n","output_type":"stream"},{"name":"stderr","text":"Training classifiers:  57%|█████▋    | 4/7 [00:03<00:02,  1.39it/s]","output_type":"stream"},{"name":"stdout","text":"\n✓ KNN: Trained in 0.03s\n  Macro F1: 0.3434\n  Weighted F1: 0.7279\n  Accuracy: 0.7512\n\n✓ KNN-CB: Trained in 0.03s\n  Macro F1: 0.4222\n  Weighted F1: 0.7431\n  Accuracy: 0.7604\n","output_type":"stream"},{"name":"stderr","text":"Training classifiers:  86%|████████▌ | 6/7 [00:03<00:00,  2.69it/s]","output_type":"stream"},{"name":"stdout","text":"\n✓ LDA: Trained in 0.03s\n  Macro F1: 0.2113\n  Weighted F1: 0.7127\n  Accuracy: 0.7478\n\n✓ NB: Trained in 0.01s\n  Macro F1: 0.2098\n  Weighted F1: 0.7122\n  Accuracy: 0.7467\n","output_type":"stream"},{"name":"stderr","text":"Training classifiers: 100%|██████████| 7/7 [00:08<00:00,  1.15s/it]\n","output_type":"stream"},{"name":"stdout","text":"\n✓ RF: Trained in 4.41s\n  Macro F1: 0.3689\n  Weighted F1: 0.7339\n  Accuracy: 0.7497\n\nResults saved to: /kaggle/working/results_House2_Th30_WindowingFalse.pkl\n\n============================================================\nConfiguration: Without_Windowing, Threshold=40\n============================================================\n\n################################################################################\nEXPERIMENT: House 2, Threshold=40, Windowing=OFF\n################################################################################\nDiscovered 6 appliances: ['dish_washer', 'electric_stove', 'fridge', 'microwave', 'washer_dryer', 'waste_disposal_unit']\nFound 7 files for house 2\n","output_type":"stream"},{"name":"stderr","text":"Loading CSV files: 100%|██████████| 7/7 [00:00<00:00, 37.88it/s]\n","output_type":"stream"},{"name":"stdout","text":"Note: Using 100,000 samples out of 292,063\nLoaded 100,000 samples\nAvailable columns: ['unnamed:_0', 'dish_washer', 'electric_stove', 'fridge', 'microwave', 'washer_dryer', 'waste_disposal_unit', 'main']\n\nUsing binary labeling without power windowing (paper baseline)\n\nThresholding Analysis (Threshold = 40):\nTotal samples: 100,000\nUnique combinations before thresholding: 14\nUnique combinations after thresholding: 9\nSamples after thresholding: 99,974 (100.0%)\nRemoved samples: 26\n\nTop 10 appliance combinations:\n  001110 : dis:0|ele:0|fri:1|mic:1|was:1|was:0 :  45,680 occurrences\n  011110 : dis:0|ele:1|fri:1|mic:1|was:1|was:0 :  43,169 occurrences\n  111110 : dis:1|ele:1|fri:1|mic:1|was:1|was:0 :   4,080 occurrences\n  101110 : dis:1|ele:0|fri:1|mic:1|was:1|was:0 :   4,018 occurrences\n  101111 : dis:1|ele:0|fri:1|mic:1|was:1|was:1 :   1,200 occurrences\n  001100 : dis:0|ele:0|fri:1|mic:1|was:0|was:0 :   1,029 occurrences\n  111111 : dis:1|ele:1|fri:1|mic:1|was:1|was:1 :     530 occurrences\n  011100 : dis:0|ele:1|fri:1|mic:1|was:0|was:0 :     216 occurrences\n  101100 : dis:1|ele:0|fri:1|mic:1|was:0|was:0 :      52 occurrences\n  111100 : dis:1|ele:1|fri:1|mic:1|was:0|was:0 :      18 occurrences\n\nFinal dataset for ML:\n  Features shape: (99974, 1)\n  Labels shape: (99974,)\n  Number of classes: 9\n\n  Class distribution (top 10):\n    Class   1:  45,680 samples - 001110\n    Class   3:  43,169 samples - 011110\n    Class   7:   4,080 samples - 111110\n    Class   5:   4,018 samples - 101110\n    Class   6:   1,200 samples - 101111\n    Class   0:   1,029 samples - 001100\n    Class   8:     530 samples - 111111\n    Class   2:     216 samples - 011100\n    Class   4:      52 samples - 101100\n\nData split:\n  Training samples: 79,979\n  Testing samples: 19,995\n  Feature dimension: 1\n  Number of classes: 9\nInitialized 7 classifiers\n\n============================================================\nTraining and Evaluating Classifiers\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"Training classifiers:  14%|█▍        | 1/7 [00:00<00:01,  4.99it/s]","output_type":"stream"},{"name":"stdout","text":"\n✓ CART: Trained in 0.14s\n  Macro F1: 0.3735\n  Weighted F1: 0.7338\n  Accuracy: 0.7503\n","output_type":"stream"},{"name":"stderr","text":"Training classifiers:  29%|██▊       | 2/7 [00:02<00:06,  1.23s/it]","output_type":"stream"},{"name":"stdout","text":"\n✓ ET: Trained in 1.64s\n  Macro F1: 0.3789\n  Weighted F1: 0.7355\n  Accuracy: 0.7521\n","output_type":"stream"},{"name":"stderr","text":"Training classifiers:  57%|█████▋    | 4/7 [00:03<00:02,  1.38it/s]","output_type":"stream"},{"name":"stdout","text":"\n✓ KNN: Trained in 0.03s\n  Macro F1: 0.3434\n  Weighted F1: 0.7279\n  Accuracy: 0.7512\n\n✓ KNN-CB: Trained in 0.03s\n  Macro F1: 0.4222\n  Weighted F1: 0.7431\n  Accuracy: 0.7604\n","output_type":"stream"},{"name":"stderr","text":"Training classifiers:  86%|████████▌ | 6/7 [00:03<00:00,  2.68it/s]","output_type":"stream"},{"name":"stdout","text":"\n✓ LDA: Trained in 0.03s\n  Macro F1: 0.2113\n  Weighted F1: 0.7127\n  Accuracy: 0.7478\n\n✓ NB: Trained in 0.01s\n  Macro F1: 0.2098\n  Weighted F1: 0.7122\n  Accuracy: 0.7467\n","output_type":"stream"},{"name":"stderr","text":"Training classifiers: 100%|██████████| 7/7 [00:08<00:00,  1.16s/it]\n","output_type":"stream"},{"name":"stdout","text":"\n✓ RF: Trained in 4.48s\n  Macro F1: 0.3689\n  Weighted F1: 0.7339\n  Accuracy: 0.7497\n\nResults saved to: /kaggle/working/results_House2_Th40_WindowingFalse.pkl\n\n============================================================\nConfiguration: Without_Windowing, Threshold=50\n============================================================\n\n################################################################################\nEXPERIMENT: House 2, Threshold=50, Windowing=OFF\n################################################################################\nDiscovered 6 appliances: ['dish_washer', 'electric_stove', 'fridge', 'microwave', 'washer_dryer', 'waste_disposal_unit']\nFound 7 files for house 2\n","output_type":"stream"},{"name":"stderr","text":"Loading CSV files: 100%|██████████| 7/7 [00:00<00:00, 40.01it/s]\n","output_type":"stream"},{"name":"stdout","text":"Note: Using 100,000 samples out of 292,063\nLoaded 100,000 samples\nAvailable columns: ['unnamed:_0', 'dish_washer', 'electric_stove', 'fridge', 'microwave', 'washer_dryer', 'waste_disposal_unit', 'main']\n\nUsing binary labeling without power windowing (paper baseline)\n\nThresholding Analysis (Threshold = 50):\nTotal samples: 100,000\nUnique combinations before thresholding: 14\nUnique combinations after thresholding: 9\nSamples after thresholding: 99,974 (100.0%)\nRemoved samples: 26\n\nTop 10 appliance combinations:\n  001110 : dis:0|ele:0|fri:1|mic:1|was:1|was:0 :  45,680 occurrences\n  011110 : dis:0|ele:1|fri:1|mic:1|was:1|was:0 :  43,169 occurrences\n  111110 : dis:1|ele:1|fri:1|mic:1|was:1|was:0 :   4,080 occurrences\n  101110 : dis:1|ele:0|fri:1|mic:1|was:1|was:0 :   4,018 occurrences\n  101111 : dis:1|ele:0|fri:1|mic:1|was:1|was:1 :   1,200 occurrences\n  001100 : dis:0|ele:0|fri:1|mic:1|was:0|was:0 :   1,029 occurrences\n  111111 : dis:1|ele:1|fri:1|mic:1|was:1|was:1 :     530 occurrences\n  011100 : dis:0|ele:1|fri:1|mic:1|was:0|was:0 :     216 occurrences\n  101100 : dis:1|ele:0|fri:1|mic:1|was:0|was:0 :      52 occurrences\n  111100 : dis:1|ele:1|fri:1|mic:1|was:0|was:0 :      18 occurrences\n\nFinal dataset for ML:\n  Features shape: (99974, 1)\n  Labels shape: (99974,)\n  Number of classes: 9\n\n  Class distribution (top 10):\n    Class   1:  45,680 samples - 001110\n    Class   3:  43,169 samples - 011110\n    Class   7:   4,080 samples - 111110\n    Class   5:   4,018 samples - 101110\n    Class   6:   1,200 samples - 101111\n    Class   0:   1,029 samples - 001100\n    Class   8:     530 samples - 111111\n    Class   2:     216 samples - 011100\n    Class   4:      52 samples - 101100\n\nData split:\n  Training samples: 79,979\n  Testing samples: 19,995\n  Feature dimension: 1\n  Number of classes: 9\nInitialized 7 classifiers\n\n============================================================\nTraining and Evaluating Classifiers\n============================================================\n","output_type":"stream"},{"name":"stderr","text":"Training classifiers:  14%|█▍        | 1/7 [00:00<00:01,  4.94it/s]","output_type":"stream"},{"name":"stdout","text":"\n✓ CART: Trained in 0.14s\n  Macro F1: 0.3735\n  Weighted F1: 0.7338\n  Accuracy: 0.7503\n","output_type":"stream"},{"name":"stderr","text":"Training classifiers:  29%|██▊       | 2/7 [00:02<00:06,  1.20s/it]","output_type":"stream"},{"name":"stdout","text":"\n✓ ET: Trained in 1.63s\n  Macro F1: 0.3789\n  Weighted F1: 0.7355\n  Accuracy: 0.7521\n","output_type":"stream"},{"name":"stderr","text":"Training classifiers:  57%|█████▋    | 4/7 [00:03<00:02,  1.42it/s]","output_type":"stream"},{"name":"stdout","text":"\n✓ KNN: Trained in 0.03s\n  Macro F1: 0.3434\n  Weighted F1: 0.7279\n  Accuracy: 0.7512\n\n✓ KNN-CB: Trained in 0.03s\n  Macro F1: 0.4222\n  Weighted F1: 0.7431\n  Accuracy: 0.7604\n","output_type":"stream"},{"name":"stderr","text":"Training classifiers:  86%|████████▌ | 6/7 [00:03<00:00,  2.73it/s]","output_type":"stream"},{"name":"stdout","text":"\n✓ LDA: Trained in 0.03s\n  Macro F1: 0.2113\n  Weighted F1: 0.7127\n  Accuracy: 0.7478\n\n✓ NB: Trained in 0.01s\n  Macro F1: 0.2098\n  Weighted F1: 0.7122\n  Accuracy: 0.7467\n","output_type":"stream"},{"name":"stderr","text":"Training classifiers: 100%|██████████| 7/7 [00:07<00:00,  1.13s/it]","output_type":"stream"},{"name":"stdout","text":"\n✓ RF: Trained in 4.38s\n  Macro F1: 0.3689\n  Weighted F1: 0.7339\n  Accuracy: 0.7497\n\nResults saved to: /kaggle/working/results_House2_Th50_WindowingFalse.pkl\n\n################################################################################\nEXPERIMENT SUMMARY\n################################################################################\n\nWith_Windowing:\n----------------------------------------\n  Threshold  5: Best = KNN     , Macro F1 = 0.5585, Classes =   7, Samples = 99,999\n  Threshold 10: Best = KNN     , Macro F1 = 0.6525, Classes =   6, Samples = 99,994\n  Threshold 20: Best = KNN     , Macro F1 = 0.6525, Classes =   6, Samples = 99,994\n  Threshold 30: Best = KNN-CB  , Macro F1 = 0.6641, Classes =   5, Samples = 99,969\n  Threshold 40: Best = KNN-CB  , Macro F1 = 0.6641, Classes =   5, Samples = 99,969\n  Threshold 50: Best = KNN-CB  , Macro F1 = 0.6641, Classes =   5, Samples = 99,969\n\nWithout_Windowing:\n----------------------------------------\n  Threshold  5: Best = KNN-CB  , Macro F1 = 0.3763, Classes =  10, Samples = 99,992\n  Threshold 10: Best = KNN-CB  , Macro F1 = 0.3763, Classes =  10, Samples = 99,992\n  Threshold 20: Best = KNN-CB  , Macro F1 = 0.4222, Classes =   9, Samples = 99,974\n  Threshold 30: Best = KNN-CB  , Macro F1 = 0.4222, Classes =   9, Samples = 99,974\n  Threshold 40: Best = KNN-CB  , Macro F1 = 0.4222, Classes =   9, Samples = 99,974\n  Threshold 50: Best = KNN-CB  , Macro F1 = 0.4222, Classes =   9, Samples = 99,974\n\nAll results saved to: /kaggle/working/all_results_house2.pkl\n\nOutput files saved to: /kaggle/working/\n\nGenerated files:\n  results_House2_Th50_WindowingFalse.pkl\n  results_House2_Th30_WindowingTrue.pkl\n  results_House2_Th5_WindowingTrue.pkl\n  results_House2_Th40_WindowingTrue.pkl\n  results_House2_Th10_WindowingTrue.pkl\n  results_House2_Th50_WindowingTrue.pkl\n  results_House2_Th40_WindowingFalse.pkl\n  results_House2_Th20_WindowingFalse.pkl\n  results_House2_Th20_WindowingTrue.pkl\n  results_House2_Th30_WindowingFalse.pkl\n  all_results_house2.pkl\n  results_House2_Th10_WindowingFalse.pkl\n  results_House2_Th5_WindowingFalse.pkl\n\n================================================================================\nEXPERIMENT COMPLETED SUCCESSFULLY!\n================================================================================\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":1}]}